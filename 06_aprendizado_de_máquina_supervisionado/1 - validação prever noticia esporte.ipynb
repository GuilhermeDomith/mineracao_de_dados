{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests,nltk, re, json\n",
    "from string import ascii_lowercase, punctuation\n",
    "from unicodedata import normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import gc \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16314, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noticias = pd.read_csv('noticias_all.csv')\n",
    "df_noticias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noticia</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carona com Deyverson: atacante do Palmeiras ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>River x Boca: final da Libertadores em Madri t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E-Brasileirão 2018\\r\\n\\r\\nAssista ao vivo à fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inauguração de estátua de Renato Gaúcho no Grê...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zagallo visita novo CT do Flamengo antes de in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             noticia  target\n",
       "0  Carona com Deyverson: atacante do Palmeiras ab...       1\n",
       "1  River x Boca: final da Libertadores em Madri t...       1\n",
       "2  E-Brasileirão 2018\\r\\n\\r\\nAssista ao vivo à fa...       1\n",
       "3  Inauguração de estátua de Renato Gaúcho no Grê...       1\n",
       "4  Zagallo visita novo CT do Flamengo antes de in...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noticias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_acentuacao(texto):\n",
    "    return normalize('NFKD', texto).encode('ASCII', 'ignore').decode()\n",
    "\n",
    "\n",
    "stopwords = requests.get('https://gist.githubusercontent.com/alopes/5358189/raw/2107d809cca6b83ce3d8e04dbd9463283025284f/stopwords.txt').text\n",
    "stopwords = [remover_acentuacao(w) for w in stopwords.split()]\n",
    "stopwords += ['ser', 'pode']\n",
    "\n",
    "with open('app/data/stopwords.json', 'w') as file:\n",
    "    json.dump(stopwords, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "def processar_texto(texto):\n",
    "    if texto is None or not texto:\n",
    "        return ''\n",
    "\n",
    "    # Trasnformação do texto em minúsculo e remoção de termo\n",
    "    texto = str(texto).lower()\n",
    "\n",
    "    # Removendo acentuação\n",
    "    texto = remover_acentuacao(texto)\n",
    "\n",
    "    # Removendo Pontuação, stopwords, palavras com número e aplicando stemming\n",
    "    texto = ' '.join([c for c in nltk.word_tokenize(texto) \n",
    "                      if (c not in punctuation) \n",
    "                      and (c not in stopwords) \n",
    "                      and not (re.match(r'.*[\\d_].*', c)) \n",
    "                      and len(c) > 2\n",
    "                     ])\n",
    "\n",
    "    return texto\n",
    "\n",
    "\n",
    "\n",
    "def vetorizar_texto(textos, vectorizer=None):\n",
    "    \n",
    "    if not vectorizer:\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            ngram_range=(1, 1),\n",
    "            min_df=0.05\n",
    "        )\n",
    "        \n",
    "        vectorizer = vectorizer.fit(textos)\n",
    "    \n",
    "    \n",
    "    tfidf_matrix = vectorizer.transform(textos)    \n",
    "    df_words = pd.DataFrame(tfidf_matrix.todense(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    return df_words, vectorizer\n",
    "\n",
    "\n",
    "\n",
    "def valida(model, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=model['model'],\n",
    "        param_grid=model['param'],\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid = grid.fit(x_train, y_train)\n",
    "    predict = grid.predict(x_test)\n",
    "    \n",
    "    return grid, metrics.roc_auc_score(y_test, predict), predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noticias['doc'] = df_noticias['noticia'].apply(processar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words, vectorizer = vetorizar_texto(df_noticias['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16314, 264)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmf = NMF(n_components=100, random_state=1)\n",
    "#nmf_w = nmf.fit_transform(df_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abert</th>\n",
       "      <th>acess</th>\n",
       "      <th>acontec</th>\n",
       "      <th>acord</th>\n",
       "      <th>afirm</th>\n",
       "      <th>agor</th>\n",
       "      <th>aind</th>\n",
       "      <th>ajud</th>\n",
       "      <th>alem</th>\n",
       "      <th>algum</th>\n",
       "      <th>...</th>\n",
       "      <th>vag</th>\n",
       "      <th>vai</th>\n",
       "      <th>val</th>\n",
       "      <th>vej</th>\n",
       "      <th>vem</th>\n",
       "      <th>venc</th>\n",
       "      <th>vend</th>\n",
       "      <th>vez</th>\n",
       "      <th>vitor</th>\n",
       "      <th>volt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103538</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abert  acess  acontec  acord  afirm  agor      aind  ajud  alem     algum  \\\n",
       "0    0.0    0.0      0.0    0.0    0.0   0.0  0.000000   0.0   0.0  0.000000   \n",
       "1    0.0    0.0      0.0    0.0    0.0   0.0  0.000000   0.0   0.0  0.000000   \n",
       "2    0.0    0.0      0.0    0.0    0.0   0.0  0.000000   0.0   0.0  0.000000   \n",
       "3    0.0    0.0      0.0    0.0    0.0   0.0  0.068283   0.0   0.0  0.079516   \n",
       "4    0.0    0.0      0.0    0.0    0.0   0.0  0.000000   0.0   0.0  0.106171   \n",
       "\n",
       "     ...     vag       vai  val      vej  vem  venc  vend  vez     vitor  \\\n",
       "0    ...     0.0  0.000000  0.0  0.48356  0.0   0.0   0.0  0.0  0.000000   \n",
       "1    ...     0.0  0.000000  0.0  0.00000  0.0   0.0   0.0  0.0  0.000000   \n",
       "2    ...     0.0  0.000000  0.0  0.00000  0.0   0.0   0.0  0.0  0.000000   \n",
       "3    ...     0.0  0.088978  0.0  0.00000  0.0   0.0   0.0  0.0  0.103538   \n",
       "4    ...     0.0  0.118804  0.0  0.13459  0.0   0.0   0.0  0.0  0.000000   \n",
       "\n",
       "       volt  \n",
       "0  0.000000  \n",
       "1  0.058348  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "\n",
       "[5 rows x 264 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_words, \n",
    "    df_noticias['target'], \n",
    "    test_size=0.33, \n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'xgb':{}, 'mlp':{}}\n",
    "\n",
    "models['xgb']['model'] = XGBClassifier(\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "models['xgb']['param'] = {\n",
    "    'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'gamma':[0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'booster':['gbtree', 'gblinear', 'dart']\n",
    "}\n",
    "\n",
    "\n",
    "models['mlp']['model'] = MLPClassifier(\n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "models['mlp']['param'] = {\n",
    "    'hidden_layer_sizes': [(10, 20 , 30), (30, 20 , 10), (20, 30), (30, 20)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "grid, score, pred = valida(models['xgb'], x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.1, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=4,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree', 'gamma': 0.1, 'max_depth': 5, 'n_estimators': 4}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9691954022988506"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591406803244842"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, score, pred = valida(models['mlp'], x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 20, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.98805, std: 0.00362, params: {'activation': 'identity', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.98881, std: 0.00250, params: {'activation': 'identity', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'sgd'},\n",
       " mean: 0.98728, std: 0.00244, params: {'activation': 'identity', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'adam'},\n",
       " mean: 0.98789, std: 0.00277, params: {'activation': 'identity', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'lbfgs'},\n",
       " mean: 0.98743, std: 0.00207, params: {'activation': 'identity', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'sgd'},\n",
       " mean: 0.98713, std: 0.00358, params: {'activation': 'identity', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'adam'},\n",
       " mean: 0.98774, std: 0.00319, params: {'activation': 'identity', 'hidden_layer_sizes': (20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.98636, std: 0.00169, params: {'activation': 'identity', 'hidden_layer_sizes': (20, 30), 'solver': 'sgd'},\n",
       " mean: 0.98667, std: 0.00358, params: {'activation': 'identity', 'hidden_layer_sizes': (20, 30), 'solver': 'adam'},\n",
       " mean: 0.98713, std: 0.00199, params: {'activation': 'identity', 'hidden_layer_sizes': (30, 20), 'solver': 'lbfgs'},\n",
       " mean: 0.98651, std: 0.00207, params: {'activation': 'identity', 'hidden_layer_sizes': (30, 20), 'solver': 'sgd'},\n",
       " mean: 0.98743, std: 0.00357, params: {'activation': 'identity', 'hidden_layer_sizes': (30, 20), 'solver': 'adam'},\n",
       " mean: 0.98820, std: 0.00339, params: {'activation': 'logistic', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.70161, std: 0.00000, params: {'activation': 'logistic', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'sgd'},\n",
       " mean: 0.98713, std: 0.00283, params: {'activation': 'logistic', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'adam'},\n",
       " mean: 0.98851, std: 0.00344, params: {'activation': 'logistic', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'lbfgs'},\n",
       " mean: 0.70161, std: 0.00000, params: {'activation': 'logistic', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'sgd'},\n",
       " mean: 0.98973, std: 0.00319, params: {'activation': 'logistic', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'adam'},\n",
       " mean: 0.98759, std: 0.00283, params: {'activation': 'logistic', 'hidden_layer_sizes': (20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.70161, std: 0.00000, params: {'activation': 'logistic', 'hidden_layer_sizes': (20, 30), 'solver': 'sgd'},\n",
       " mean: 0.98774, std: 0.00313, params: {'activation': 'logistic', 'hidden_layer_sizes': (20, 30), 'solver': 'adam'},\n",
       " mean: 0.98805, std: 0.00271, params: {'activation': 'logistic', 'hidden_layer_sizes': (30, 20), 'solver': 'lbfgs'},\n",
       " mean: 0.70161, std: 0.00000, params: {'activation': 'logistic', 'hidden_layer_sizes': (30, 20), 'solver': 'sgd'},\n",
       " mean: 0.98789, std: 0.00319, params: {'activation': 'logistic', 'hidden_layer_sizes': (30, 20), 'solver': 'adam'},\n",
       " mean: 0.98743, std: 0.00213, params: {'activation': 'tanh', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.98866, std: 0.00250, params: {'activation': 'tanh', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'sgd'},\n",
       " mean: 0.98743, std: 0.00244, params: {'activation': 'tanh', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'adam'},\n",
       " mean: 0.98759, std: 0.00150, params: {'activation': 'tanh', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'lbfgs'},\n",
       " mean: 0.98820, std: 0.00250, params: {'activation': 'tanh', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'sgd'},\n",
       " mean: 0.98728, std: 0.00319, params: {'activation': 'tanh', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'adam'},\n",
       " mean: 0.98820, std: 0.00355, params: {'activation': 'tanh', 'hidden_layer_sizes': (20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.98621, std: 0.00150, params: {'activation': 'tanh', 'hidden_layer_sizes': (20, 30), 'solver': 'sgd'},\n",
       " mean: 0.98682, std: 0.00341, params: {'activation': 'tanh', 'hidden_layer_sizes': (20, 30), 'solver': 'adam'},\n",
       " mean: 0.98789, std: 0.00241, params: {'activation': 'tanh', 'hidden_layer_sizes': (30, 20), 'solver': 'lbfgs'},\n",
       " mean: 0.98636, std: 0.00185, params: {'activation': 'tanh', 'hidden_layer_sizes': (30, 20), 'solver': 'sgd'},\n",
       " mean: 0.98728, std: 0.00339, params: {'activation': 'tanh', 'hidden_layer_sizes': (30, 20), 'solver': 'adam'},\n",
       " mean: 0.98912, std: 0.00383, params: {'activation': 'relu', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.98713, std: 0.00135, params: {'activation': 'relu', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'sgd'},\n",
       " mean: 0.98789, std: 0.00292, params: {'activation': 'relu', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'adam'},\n",
       " mean: 0.98805, std: 0.00263, params: {'activation': 'relu', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'lbfgs'},\n",
       " mean: 0.98789, std: 0.00121, params: {'activation': 'relu', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'sgd'},\n",
       " mean: 0.98820, std: 0.00339, params: {'activation': 'relu', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'adam'},\n",
       " mean: 0.98759, std: 0.00433, params: {'activation': 'relu', 'hidden_layer_sizes': (20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.98651, std: 0.00108, params: {'activation': 'relu', 'hidden_layer_sizes': (20, 30), 'solver': 'sgd'},\n",
       " mean: 0.98835, std: 0.00229, params: {'activation': 'relu', 'hidden_layer_sizes': (20, 30), 'solver': 'adam'},\n",
       " mean: 0.98759, std: 0.00307, params: {'activation': 'relu', 'hidden_layer_sizes': (30, 20), 'solver': 'lbfgs'},\n",
       " mean: 0.98605, std: 0.00094, params: {'activation': 'relu', 'hidden_layer_sizes': (30, 20), 'solver': 'sgd'},\n",
       " mean: 0.98789, std: 0.00301, params: {'activation': 'relu', 'hidden_layer_sizes': (30, 20), 'solver': 'adam'}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9897318007662835"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863201214620978"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba = grid.best_estimator_.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00626   , 0.99374   ],\n",
       "       [0.00630827, 0.99369173],\n",
       "       [0.9983204 , 0.0016796 ],\n",
       "       ...,\n",
       "       [0.99832031, 0.00167969],\n",
       "       [0.99829651, 0.00170349],\n",
       "       [0.00630133, 0.99369867]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sem aplicar Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noticias['doc2'] = df_noticias['noticia'].apply(processar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words, vectorizer = vetorizar_texto(df_noticias['doc2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16314, 492)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_words, \n",
    "    df_noticias['target'], \n",
    "    test_size=0.33, \n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "grid, score, pred = valida(models['xgb'], x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.4, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=8,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gblinear', 'gamma': 0.4, 'max_depth': 3, 'n_estimators': 8}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984901134619247"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.4, 'max_depth': 3, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.1, 'max_depth': 3, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.2, 'max_depth': 3, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.2, 'max_depth': 4, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.2, 'max_depth': 6, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.5, 'max_depth': 3, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.1, 'max_depth': 7, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.3, 'max_depth': 6, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0, 'max_depth': 8, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0, 'max_depth': 7, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.3, 'max_depth': 5, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.4, 'max_depth': 6, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.5, 'max_depth': 4, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.3, 'max_depth': 8, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0, 'max_depth': 6, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.4, 'max_depth': 4, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.5, 'max_depth': 6, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.3, 'max_depth': 3, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.3, 'max_depth': 4, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.5, 'max_depth': 8, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.1, 'max_depth': 8, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0, 'max_depth': 4, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0, 'max_depth': 5, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.1, 'max_depth': 4, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.4, 'max_depth': 8, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.3, 'max_depth': 7, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.1, 'max_depth': 6, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0, 'max_depth': 3, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.4, 'max_depth': 7, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.2, 'max_depth': 7, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.1, 'max_depth': 5, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.2, 'max_depth': 8, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.4, 'max_depth': 5, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.5, 'max_depth': 5, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.5, 'max_depth': 7, 'n_estimators': 8},\n",
       " mean: 0.99849, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.2, 'max_depth': 5, 'n_estimators': 8},\n",
       " mean: 0.99841, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.3, 'max_depth': 7, 'n_estimators': 7},\n",
       " mean: 0.99841, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.2, 'max_depth': 6, 'n_estimators': 7},\n",
       " mean: 0.99841, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0, 'max_depth': 7, 'n_estimators': 7},\n",
       " mean: 0.99841, std: 0.00006, params: {'booster': 'gblinear', 'gamma': 0.1, 'max_depth': 3, 'n_estimators': 7}]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = grid.grid_scores_\n",
    "scores.sort(key=lambda x: x[1], reverse=True)\n",
    "scores[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, score, pred = valida(models['mlp'], x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(20, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'hidden_layer_sizes': (20, 30), 'solver': 'adam'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.99973, std: 0.00007, params: {'activation': 'relu', 'hidden_layer_sizes': (20, 30), 'solver': 'adam'},\n",
       " mean: 0.99972, std: 0.00008, params: {'activation': 'relu', 'hidden_layer_sizes': (30, 20), 'solver': 'adam'},\n",
       " mean: 0.99970, std: 0.00006, params: {'activation': 'relu', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'adam'},\n",
       " mean: 0.99970, std: 0.00005, params: {'activation': 'relu', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'adam'},\n",
       " mean: 0.99970, std: 0.00006, params: {'activation': 'logistic', 'hidden_layer_sizes': (20, 30), 'solver': 'adam'},\n",
       " mean: 0.99969, std: 0.00006, params: {'activation': 'logistic', 'hidden_layer_sizes': (30, 20), 'solver': 'adam'},\n",
       " mean: 0.99969, std: 0.00004, params: {'activation': 'logistic', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'adam'},\n",
       " mean: 0.99969, std: 0.00006, params: {'activation': 'logistic', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'adam'},\n",
       " mean: 0.99968, std: 0.00008, params: {'activation': 'tanh', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'adam'},\n",
       " mean: 0.99967, std: 0.00009, params: {'activation': 'tanh', 'hidden_layer_sizes': (30, 20), 'solver': 'adam'},\n",
       " mean: 0.99967, std: 0.00010, params: {'activation': 'identity', 'hidden_layer_sizes': (30, 20), 'solver': 'adam'},\n",
       " mean: 0.99966, std: 0.00008, params: {'activation': 'identity', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'adam'},\n",
       " mean: 0.99966, std: 0.00010, params: {'activation': 'identity', 'hidden_layer_sizes': (20, 30), 'solver': 'adam'},\n",
       " mean: 0.99965, std: 0.00010, params: {'activation': 'tanh', 'hidden_layer_sizes': (20, 30), 'solver': 'adam'},\n",
       " mean: 0.99965, std: 0.00011, params: {'activation': 'tanh', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'adam'},\n",
       " mean: 0.99965, std: 0.00003, params: {'activation': 'tanh', 'hidden_layer_sizes': (20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.99965, std: 0.00011, params: {'activation': 'identity', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'adam'},\n",
       " mean: 0.99964, std: 0.00005, params: {'activation': 'relu', 'hidden_layer_sizes': (10, 20, 30), 'solver': 'lbfgs'},\n",
       " mean: 0.99963, std: 0.00013, params: {'activation': 'tanh', 'hidden_layer_sizes': (30, 20, 10), 'solver': 'sgd'},\n",
       " mean: 0.99962, std: 0.00008, params: {'activation': 'identity', 'hidden_layer_sizes': (20, 30), 'solver': 'lbfgs'}]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = grid.grid_scores_\n",
    "scores.sort(key=lambda x: x[1], reverse=True)\n",
    "scores[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997282346559676"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914073494414334"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba = grid.best_estimator_.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.87062571e-05, 9.99981294e-01],\n",
       "       [6.72742732e-05, 9.99932726e-01],\n",
       "       [9.99999345e-01, 6.54623952e-07],\n",
       "       ...,\n",
       "       [9.99999904e-01, 9.60787392e-08],\n",
       "       [9.99388052e-01, 6.11947637e-04],\n",
       "       [1.00000000e+00, 9.42578874e-11]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999999999057421, 9.425788739839954e-11]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba.tolist()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%.7f\" % x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0006119'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_formatter(predict_proba[-2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
